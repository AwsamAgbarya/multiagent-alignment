# @package _global_

# Experiment settings
experiment:
  name: llama_logiqa_dataset
  description: "Configuration for the extraction of datasets for llama-based agents debated on logiqa"
  debug: false
  iteration: 1

# Dataset configuration
dataset:
  input:
    name: llama_logiqa_debate
    path: /netscratch/${user.name}/multiagent-alignment/outputs/llama/debate/logiqa/
    format: multiple_choice
    type: QA
    num_of_generators: 3
    max_rows: 1000
  output:
    path: /netscratch/${user.name}/multiagent-alignment/outputs/llama/dataset_gen/logiqa/  

# Model ids
model:
  name: llama
  ids:
    - Gen1_2
    - Gen2_2
    - Gen3_2
    - Critic1_2
    - Critic2_2
    - Critic3_2

# Hydra configuration
hydra:
  run:
    dir: /netscratch/${user.name}/multiagent-alignment/outputs/llama/dataset_gen/logiqa/

# User's username directory
user:
  name: aagbaria

# Optional parameters 
logging:
  level: INFO
  save_outputs: true
  log_frequency: 1  # Log every n steps

gpt_style: false

# Extra training parameters
training_config:
  # Examples
  # output_dir: "./"
  # num_train_epochs: 1
  # max_seq_length: 2048
  # prompt_length: 516
  # per_device_train_batch_size: 4
  # per_device_eval_batch_size: 1
  # gradient_accumulation_steps: 4
  # gradient_checkpointing: False 
  # optim: "adamw_torch_fused"
  # learning_rate: 5e-6
  # max_grad_norm: 1
  # warmup_ratio: 0.1
  # lr_scheduler_type: "cosine"
  # logging_steps: 4
  # save_steps: 4
  # save_total_limit: 1
  # evaluation_strategy: "steps"
  # eval_steps: 4
  # bf16: True
  # tf32: True
  # push_to_hub: False
  # gradient_checkpointing_use_reentrant: False